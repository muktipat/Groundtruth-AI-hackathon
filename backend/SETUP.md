# AuraCX Backend - Setup & Development Guide

## Quick Start

### 1. Prerequisites
- Python 3.11+
- OpenAI API Key
- pip or conda

### 2. Installation

```bash
# Clone the repository
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### 3. Run the Server

```bash
python run.py
```

The API will be available at:
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/docs (Swagger UI)
- **ReDoc**: http://localhost:8000/redoc

### 4. Test the API

**Using the test client:**
```bash
python client.py
```

**Using curl:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Is your store open?",
    "customer_id": "cust_001",
    "location": {
      "latitude": 40.7128,
      "longitude": -74.0060
    }
  }'
```

**Using Python requests:**
```python
import requests

response = requests.post(
    "http://localhost:8000/chat",
    json={
        "message": "Is your store open?",
        "customer_id": "cust_001",
        "location": {
            "latitude": 40.7128,
            "longitude": -74.0060
        }
    }
)
print(response.json())
```

## Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/              # Specialized agents
â”‚   â”‚   â”œâ”€â”€ intent_agent.py         # Intent detection
â”‚   â”‚   â”œâ”€â”€ store_agent.py          # Store info
â”‚   â”‚   â”œâ”€â”€ inventory_agent.py      # Stock info
â”‚   â”‚   â”œâ”€â”€ order_agent.py          # Order tracking
â”‚   â”‚   â””â”€â”€ offers_agent.py         # Coupons & offers
â”‚   â”œâ”€â”€ services/            # High-level services
â”‚   â”‚   â””â”€â”€ synthesizer.py          # Agent orchestration
â”‚   â”œâ”€â”€ utils/               # Utilities
â”‚   â”‚   â”œâ”€â”€ pii_masker.py           # Privacy protection
â”‚   â”‚   â”œâ”€â”€ llm_client.py           # OpenAI integration
â”‚   â”‚   â””â”€â”€ logger.py               # Logging
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py              # Pydantic schemas
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â””â”€â”€ config.py            # Configuration
â”œâ”€â”€ run.py                   # Server entrypoint
â”œâ”€â”€ client.py                # Test client
â”œâ”€â”€ test_agents.py           # Unit tests
â”œâ”€â”€ Dockerfile               # Docker config
â”œâ”€â”€ docker-compose.yml       # Docker Compose config
â””â”€â”€ requirements.txt         # Python dependencies
```

## Architecture

### Two-Mode Design

1. **Tooling Mode** (Current Implementation)
   - Fast, deterministic agents
   - Handles: store hours, stock, orders, offers
   - No hallucination risk

2. **RAG Mode** (Future)
   - Complex/vague queries
   - Uses vector search + reranking
   - Deployed by your friend

### Agent Workflow

```
User Message
    â†“
PII Masking
    â†“
Intent Detection â†’ Emotion Analysis
    â†“
Route to Agents
    â”œâ”€â”€ Store Agent (if store_hours)
    â”œâ”€â”€ Inventory Agent (if stock_check)
    â”œâ”€â”€ Order Agent (if order_status)
    â”œâ”€â”€ Offers Agent (if recommendations)
    â””â”€â”€ ...
    â†“
Synthesizer Combines Results
    â†“
LLM Generates Response
    â†“
Return ChatResponse
```

## Configuration

### Environment Variables (.env)

```env
# Required
OPENAI_API_KEY=sk-...your-key...

# Optional
ENVIRONMENT=development          # development or production
LOG_LEVEL=INFO                  # DEBUG, INFO, WARNING, ERROR
```

### Model Configuration (app/config.py)

```python
GPT_MODEL = "gpt-4-turbo-preview"  # Model to use
TEMPERATURE = 0.7                 # Creativity level
MAX_TOKENS = 2048                # Response length
CONFIDENCE_THRESHOLD = 0.7        # Escalation threshold
```

## API Reference

### Endpoints

#### 1. Health Check
```
GET /health

Response:
{
  "status": "healthy",
  "timestamp": "2025-12-03T10:00:00",
  "environment": "development"
}
```

#### 2. Chat
```
POST /chat

Request:
{
  "message": "Is your store open?",
  "customer_id": "cust_001",
  "location": {
    "latitude": 40.7128,
    "longitude": -74.0060,
    "address": "New York, NY"
  },
  "customer_profile": {
    "customer_id": "cust_001",
    "location": {
      "latitude": 40.7128,
      "longitude": -74.0060
    },
    "past_visits": [],
    "preferences": {},
    "weather_context": "cold"
  }
}

Response:
{
  "message": "The Starbucks Downtown is open until 9 PM.",
  "intent": "store_hours",
  "emotion": "neutral",
  "confidence": 0.95,
  "mode": "tooling",
  "data": {
    "store_hours": {...},
    "nearby_stores": [...]
  },
  "requires_escalation": false,
  "timestamp": "2025-12-03T10:00:00"
}
```

## Supported Intents

1. **store_hours** - Query store operating hours
2. **stock_check** - Check product availability
3. **order_status** - Track order status
4. **location_recommendation** - Find nearby stores
5. **product_recommendation** - Get personalized suggestions
6. **other** - Escalate or use RAG mode

## Testing

### Run Unit Tests
```bash
pytest test_agents.py -v
```

### Run with Coverage
```bash
pytest test_agents.py --cov=app --cov-report=html
```

## Docker

### Build Image
```bash
docker build -t auracrx-backend:latest .
```

### Run Container
```bash
docker run -p 8000:8000 \
  -e OPENAI_API_KEY=sk-... \
  auracrx-backend:latest
```

### Using Docker Compose
```bash
OPENAI_API_KEY=sk-... docker-compose up
```

## Development

### Adding a New Agent

1. Create `app/agents/new_agent.py`
2. Implement agent class with methods
3. Add to `app/agents/__init__.py`
4. Update Synthesizer routing logic
5. Add tests in `test_agents.py`

### Example Agent
```python
from app.utils.logger import get_logger

logger = get_logger(__name__)

class NewAgent:
    @staticmethod
    def do_something(data):
        logger.info("Processing...")
        return {"result": "data"}
```

## Troubleshooting

### OpenAI API Key Error
```
ValueError: OPENAI_API_KEY not set in environment
```
â†’ Make sure to set OPENAI_API_KEY in .env file

### Port Already in Use
```
OSError: [Errno 48] Address already in use
```
â†’ Change port in `run.py` or kill existing process

### Slow Responses
â†’ Check OpenAI API status
â†’ Reduce MAX_TOKENS in config.py
â†’ Use faster model (gpt-3.5-turbo)

## Production Deployment

### Prerequisites
- Docker and Docker Compose
- GPU (optional, for faster inference)
- Monitoring setup (Prometheus, ELK, etc.)

### Steps
1. Set ENVIRONMENT=production in .env
2. Disable LOG_LEVEL=WARNING
3. Use `docker-compose up -d`
4. Set up reverse proxy (Nginx)
5. Enable HTTPS/TLS
6. Add rate limiting
7. Set up monitoring

## Next Steps

- [ ] Integrate with real database
- [ ] Add authentication (JWT)
- [ ] Implement rate limiting
- [ ] Add request/response logging
- [ ] Set up monitoring & alerts
- [ ] Integrate RAG mode
- [ ] Add frontend
- [ ] Performance optimization

## Support

For issues or questions, please check:
1. The main README.md
2. API documentation at /docs
3. Test examples in client.py
4. Issue tracker on GitHub

---

**Happy coding! ðŸš€**
